#!/usr/bin/env python

import sys

# HACK
sys.path.extend(['/vagrant', '/vagrant/env/lib/python2.7/site-packages'])

import argparse
import hashlib
import json
import os
import signal
from subprocess import call
import time
import uuid

from tot import fs
from tot.config import get_user_mount_dir
from tot.config import setup_config
from tot.config import Session
from tot.logger import Logger
from tot.logger import read_logs
from tot.tracer.strace import STraceTracer


def hash_file(path):
    blocklen = 1024 * 4

    with open(path) as infile:
        m = hashlib.sha1()
        while True:
            block = infile.read(blocklen)
            if len(block) == 0:
                break
            m.update(block)
    file_hash = m.digest().encode("hex")
    return file_hash


def import_logs(args):
    from tot.db import TotDatabase

    db = TotDatabase(args.db)

    for log_file in args.log_files:
        db.load(read_logs(log_file))

    return 0


def format_timestamp(timestamp):
    return timestamp.strftime('%Y-%M-%d %H:%M:%S')


def format_argv(progname, argv):
    # TODO: Escape strings correctly.
    try:
        argv = json.loads(argv)
        return ' '.join([progname] + argv[1:])
    except ValueError:
        return '{} {}'.format(progname, argv)



def is_file_shown(filename):
    hidden_paths = [
        '/dev/',
        '/etc/',
        '/lib/',
        '/proc/',
        '/usr/lib/',
    ]

    for hidden_path in hidden_paths:
        if filename.startswith(hidden_path):
            return False

    return True

def get_proc_files(db, proc_id):
    from tot.db import ProcessFile

    proc_files = (db.session.query(ProcessFile)
             .filter_by(process=proc_id))

    for proc_file in proc_files:
        if is_file_shown(proc_file.filename):
            yield proc_file


def show_procs(db, proc_id=None, parent=None, depth=0, level='full'):
    from tot.db import Process
    from tot.db import ProcessFile

    if proc_id:
        procs = (db.session.query(Process)
                 .filter_by(id=proc_id)
                 .order_by('start_time'))
    else:
        # Show all top-level processes.
        procs = (db.session.query(Process)
                 .filter_by(parent=parent)
                 .order_by('start_time'))

    for proc in procs:
        print '{} {}{} $ {}'.format(
            format_timestamp(proc.start_time),
            proc.id[:8],
            ' ' * (depth * 2),
            format_argv(proc.progname, proc.argv))

        if level == 'full':
            parent_id = proc.parent[:8] if proc.parent else 'None'
            print '  pid={}, parent={} '.format(proc.pid, parent_id)

            #files = (db.session.query(ProcessFile)
            #         .filter_by(process=proc.id))
            for pf in get_proc_files(db, proc.id):
                print '  {}: {} ({})'.format(
                    pf.action, pf.filename, pf.hash[:8])
            print

        show_procs(db, parent=proc.id, depth=depth + 1,
                   level=level)


def show_file(db, filename=None, hash=None):
    from tot.db import Process
    from tot.db import ProcessFile

    if filename:
        hash = hash_file(filename)

    process_files = (db.session.query(ProcessFile)
                     .filter_by(hash=hash)
                     .order_by('timestamp'))

    if process_files.count() == 0:
        print 'Unknown file: {}'.format(filename)
        return

    process_ids = [pf.process for pf in process_files]
    procs = (db.session.query(Process)
             .filter(Process.id.in_(process_ids))
             .order_by('start_time'))

    for proc in procs:
        print '{} {} $ {}'.format(
            format_timestamp(proc.start_time),
            proc.id[:8],
            format_argv(proc.progname, proc.argv))
        print '  proc:  pid={}'.format(proc.pid)

        for pf in process_files:
            if pf.process == proc.id:
                print '  {}: {} ({})'.format(
                    pf.action, pf.filename, pf.hash[:8])


def unique(items, key=lambda x: x):
    seen = set()
    for item in items:
        if item not in seen:
            yield item
            seen.add(item)

def show(args):
    from tot.db import TotDatabase
    from tot.db import Process
    from tot.db import ProcessFile

    db = TotDatabase(args.db)

    if not args.objects:
        # Show a list of all processes.
        # TODO: use a PAGER to avoid printing too much. Similar to git log.
        show_procs(db)

    for obj in args.objects:
        shown = False

        # Try to display object as a local filename.
        if os.path.exists(obj):
            show_file(db, obj)
            continue

        # Try to display object as a file hash.
        proc_files = (db.session.query(ProcessFile)
                      .filter(ProcessFile.hash.contains(obj))
                      .order_by('timestamp'))
        proc_files = list(unique(proc_files, key=lambda pf: pf.hash))
        for proc_file in proc_files:
            if proc_file.hash.startswith(obj):
                show_file(db, hash=proc_file.hash)
                shown = True

        if shown:
            continue

        # Try to display object as a process id.
        procs = (db.session.query(Process)
                 .filter(Process.id.contains(obj))
                 .order_by('start_time'))
        for proc in procs:
            if proc.id.startswith(obj):
                show_procs(db, proc_id=proc.id)
                shown = True

        if shown:
            continue

    return 0


def main(argv):
    # Build command-line parser.
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers()

    parser.add_argument('--log', default='tot.log',
                        help='log file')
    parser.add_argument('--log-fs', default='tot-fs.log',
                        help='log fs file')
    parser.add_argument('--db', default='tot.db', help='database file')
    parser.add_argument('--chroot')

    # log command.
    parser_log = subparsers.add_parser(
        'log', help='log command')
    parser_log.set_defaults(func=None)

    # import command.
    parser_import = subparsers.add_parser(
        'import', help='import logs')
    parser_import.add_argument('log_files', nargs='*',
                               help='log files to import')
    parser_import.set_defaults(func=import_logs)

    # show command.
    parser_import = subparsers.add_parser(
        'show', help='import logs')
    parser_import.add_argument('objects', nargs='*',
                               help='files or processes to query')
    parser_import.set_defaults(func=show)

    # Parse command line arguments.
    args, rest = parser.parse_known_args(argv)

    if args.func:
        return args.func(args)

    # Setup user config.
    setup_config()
    mount_dir = get_user_mount_dir()

    if not args.chroot:
        # Need to setup chroot fs.

        session = Session()

        # Setup fs shim.
        child_pid = os.fork()
        if child_pid == 0:
            logger_fs = Logger(open(args.log_fs, 'a'))
            tot_fs = fs.TotFS(session, logger_fs.log)
            tot_fs.mount(mount_dir)
            # Runs forever.

        assert child_pid != 0

        # Wait for mount to setup.
        while not os.listdir(mount_dir):
            time.sleep(.01)

        # Rexecute within chroot.
        tot = os.path.abspath(__file__)
        retcode = call(
            ['tot-chroot', tot, '--chroot', str(session.id)] + sys.argv[1:])

        # TODO: use counter scheme unmount only when all tot processes for a
        # user are done.
        # Kill mount process.
        os.kill(child_pid, signal.SIGKILL)
        fs.unmount(mount_dir)

        return retcode

    # chroot fs is already in place, start tracing.
    # Setup logger.
    logger = Logger(open(args.log, 'a'))

    # Run tracer and log events.
    cmd = rest
    session = Session(id=args.chroot)
    tracer = STraceTracer(session)
    for row in tracer.trace(cmd):
        logger.log(row)

    return tracer.retcode


if __name__ == '__main__':
    sys.exit(main(sys.argv[1:]))
